{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3431319e-2e6b-43c1-a2f6-61ccba592c21",
   "metadata": {},
   "source": [
    "## Evaluating a vectorial function on CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b9d9256-a661-4643-9fbb-dda90038fabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU dtypes: float32 float32 float32 float32 float32\n",
      "CuPy version: 13.6.0\n",
      "GPU device: NVIDIA GeForce GTX 1080\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# GPU libs\n",
    "import cupy as cp\n",
    "from numba import njit, vectorize, cuda\n",
    "\n",
    "# Reproducibilidad\n",
    "np.random.seed(42)\n",
    "\n",
    "# Tamaño (como en la práctica)\n",
    "size = 5_000_000\n",
    "\n",
    "# Datos en CPU (float32 = simple precisión)\n",
    "a_cpu = np.random.rand(size).astype(np.float32)\n",
    "b_cpu = np.random.rand(size).astype(np.float32)\n",
    "\n",
    "# Constantes (float32)\n",
    "a = np.float32(3.5)\n",
    "b = np.float32(2.8)\n",
    "c = np.float32(10.0)\n",
    "\n",
    "print(\"CPU dtypes:\", a_cpu.dtype, b_cpu.dtype, a.dtype, b.dtype, c.dtype)\n",
    "\n",
    "# Info GPU\n",
    "print(\"CuPy version:\", cp.__version__)\n",
    "print(\"GPU device:\", cp.cuda.runtime.getDeviceProperties(0)[\"name\"].decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48935b33-fb82-4c73-9949-f26c86dc60aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "def gpu_time_ms(fn, n_repeat=10, n_warmup=3):\n",
    "    \"\"\"Mide tiempo en GPU con CUDA Events (ms).\"\"\"\n",
    "    # Warm-up (para evitar medir inicialización/compilación)\n",
    "    for _ in range(n_warmup):\n",
    "        fn()\n",
    "    cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "    times = []\n",
    "    for _ in range(n_repeat):\n",
    "        start = cp.cuda.Event()\n",
    "        end = cp.cuda.Event()\n",
    "        start.record()\n",
    "        fn()\n",
    "        end.record()\n",
    "        end.synchronize()\n",
    "        times.append(cp.cuda.get_elapsed_time(start, end))  # ms\n",
    "    return np.array(times, dtype=np.float64)\n",
    "\n",
    "def show_stats(label, times_ms):\n",
    "    print(\n",
    "        f\"{label}: mean={times_ms.mean():.3f} ms | std={times_ms.std():.3f} ms | \"\n",
    "        f\"min={times_ms.min():.3f} ms | max={times_ms.max():.3f} ms\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d142183-b6bb-42e7-ba9d-35bf0f91dc0c",
   "metadata": {},
   "source": [
    "### CPU: plain and numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c2952fc-ee47-4ebe-a8a1-6deaf728f185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU numba njit:\n",
      "2.56 ms ± 99.5 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "CPU numpy ufunc:\n",
      "8.98 ms ± 331 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n",
      "CPU numpy expresión directa:\n",
      "8.62 ms ± 55.2 μs per loop (mean ± std. dev. of 2 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def grade2_vector(x, y, a, b, c):\n",
    "    z = np.empty(x.size, dtype=np.float32)\n",
    "    for i in range(x.size):\n",
    "        z[i] = a * x[i] * x[i] + b * y[i] + c\n",
    "    return z\n",
    "\n",
    "def grade2_ufunc(x, y, a, b, c):\n",
    "    return a * x**2 + b * y + c\n",
    "\n",
    "# Warm-up (muy importante para Numba)\n",
    "_ = grade2_vector(a_cpu[:10], b_cpu[:10], a, b, c)\n",
    "\n",
    "# Guardar salida (si el profesor lo llama c_cpu, lo dejamos así)\n",
    "c_cpu = grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "print(\"CPU numba njit:\")\n",
    "%timeit -n 5 -r 2 grade2_vector(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "print(\"CPU numpy ufunc:\")\n",
    "%timeit -n 5 -r 2 grade2_ufunc(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "print(\"CPU numpy expresión directa:\")\n",
    "%timeit -n 5 -r 2 (a * a_cpu**2 + b * b_cpu + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6601c851-8ad5-487c-9cba-baa61e728315",
   "metadata": {},
   "source": [
    "Celda 2 — CuPy con copia CPU↔GPU (baseline GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d3c131b-de4d-4901-b0ca-253f5e4932a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy ufunc CON copia (CPU<->GPU incluido): mean=7.128 ms | std=0.052 ms | min=7.074 ms | max=7.246 ms\n"
     ]
    }
   ],
   "source": [
    "# Ufunc en CuPy tipo \"elementwise\"\n",
    "grade2_cupy_ufunc = cp.ElementwiseKernel(\n",
    "    in_params='float32 x, float32 y, float32 a, float32 b, float32 c',\n",
    "    out_params='float32 z',\n",
    "    operation='z = a * x * x + b * y + c;',\n",
    "    name='grade2_cupy_ufunc'\n",
    ")\n",
    "\n",
    "def cupy_with_copy():\n",
    "    # Copia CPU->GPU\n",
    "    xg = cp.asarray(a_cpu)\n",
    "    yg = cp.asarray(b_cpu)\n",
    "    # Compute en GPU\n",
    "    zg = grade2_cupy_ufunc(xg, yg, a, b, c)\n",
    "    # Copia GPU->CPU (incluida en el tiempo “con copia”)\n",
    "    _ = cp.asnumpy(zg)\n",
    "\n",
    "# Warm-up\n",
    "cupy_with_copy()\n",
    "cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "\n",
    "# Medición\n",
    "times = gpu_time_ms(cupy_with_copy, n_repeat=10, n_warmup=3)\n",
    "show_stats(\"CuPy ufunc CON copia (CPU<->GPU incluido)\", times)\n",
    "times = gpu_time_ms(cupy_with_copy, n_repeat=10, n_warmup=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a668f0-6d71-4061-82dd-f2405dffbdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "920825fd-3178-41f1-a8db-a718896cb321",
   "metadata": {},
   "source": [
    " Celda 3 — CuPy sin copia (crear directamente en GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "644bc146-5e85-4d55-8e32-1806295d65de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy SIN copia: mean=1.666 ms | std=0.002 ms | min=1.661 ms | max=1.668 ms\n"
     ]
    }
   ],
   "source": [
    "def cupy_no_copy():\n",
    "    # Datos en GPU directamente (sin transferencia desde CPU)\n",
    "    xg = cp.random.random(size).astype(cp.float32)\n",
    "    yg = cp.random.random(size).astype(cp.float32)\n",
    "    zg = grade2_cupy_ufunc(xg, yg, a, b, c)\n",
    "    # NO hacemos asnumpy aquí para no contar copias\n",
    "    return zg\n",
    "\n",
    "# Warm-up\n",
    "_ = cupy_no_copy()\n",
    "cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "#Medición\n",
    "times = gpu_time_ms(cupy_no_copy, n_repeat=10, n_warmup=3)\n",
    "show_stats(\"CuPy SIN copia\", times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5cfc33-fe16-469d-94ba-51f79ed63af2",
   "metadata": {},
   "source": [
    "Celda 4 — Numba en GPU usando @vectorize(target='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f593d4a-8c7c-4f33-8afb-9f4feb880458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numba CON copia: mean=8.851 ms | std=1.213 ms | min=7.555 ms | max=10.744 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@vectorize(['float32(float32, float32, float32, float32, float32)'], target='cuda')\n",
    "def grade2_numba_cuda(x, y, a, b, c):\n",
    "    return a * x * x + b * y + c\n",
    "\n",
    "def numba_with_copy():\n",
    "    # Si le pasas NumPy arrays, N    # Si le pasas NumPy arrays, Numba hace copias automáticas host<->device\n",
    "    _ = grade2_numba_cuda(a_cpu, b_cpu, a, b, c)\n",
    "\n",
    "# Warm-up\n",
    "numba_with_copy()\n",
    "cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "#Medición\n",
    "times = gpu_time_ms(numba_with_copy, n_repeat=10, n_warmup=3)\n",
    "show_stats(\"Numba CON copia\", times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed74a82-6ca8-45c1-8c0c-78c90a66cef9",
   "metadata": {},
   "source": [
    "Celda 5 — Numba @vectorize(target='cuda') SIN CONTAR COPIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3557c30e-60f3-4e37-a4a8-4d032e49be13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numba SIN copia: mean=1.612 ms | std=0.576 ms | min=1.129 ms | max=2.460 ms\n"
     ]
    }
   ],
   "source": [
    "# Copia manual FUERA del timing\n",
    "xg = cp.asarray(a_cpu)\n",
    "yg = cp.asarray(b_cpu)\n",
    "cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "def numba_no_copy_counted():\n",
    "    # al pasar arrays que viven en GPU (cupy), Numba puede operar via __cuda_array_interface__\n",
    "    _ = grade2_numba_cuda(xg, yg, a, b, c)\n",
    "\n",
    "# Warm-up\n",
    "numba_no_copy_counted()\n",
    "cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "#Medición\n",
    "times = gpu_time_ms(numba_no_copy_counted, n_repeat=10, n_warmup=3)\n",
    "show_stats(\"Numba SIN copia\", times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca16e1f-80fd-4114-97ed-abc269b5bd2b",
   "metadata": {},
   "source": [
    "CELDA 8 — Verificación de resultados (CPU vs GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24217865-4151-4f58-8bec-fbfe5fa946b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CuPy OK?: True\n"
     ]
    }
   ],
   "source": [
    "# Referencia CPU (NumPy ufunc)\n",
    "z_ref = grade2_ufunc(a_cpu, b_cpu, a, b, c).astype(np.float32)\n",
    "\n",
    "# CuPy con copia: obtenemos salida CPU y comparamos\n",
    "xg2 = cp.asarray(a_cpu)\n",
    "yg2 = cp.asarray(b_cpu)\n",
    "zg2 = grade2_cupy_ufunc(xg2, yg2, a, b, c)\n",
    "z_cupy = cp.asnumpy(zg2).astype(np.float32)\n",
    "\n",
    "print(\"CuPy OK?:\", np.allclose(z_ref, z_cupy, rtol=1e-5, atol=1e-6))\n",
    "\n",
    "# Numba CUDA (con# Numba CUDA (con arrays CPU, devuelve resultado en host normalmente)\n",
    "z_numba = grade2_numba_cuda(a_cpu, b_cpu, a, b, c).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c978daa8-8cd6-443e-a5fc-5ab235ffb7d9",
   "metadata": {},
   "source": [
    "Celda 6 — Conclusiones (texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da03abf6-a23b-4c51-ba97-0d19a79c4870",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusiones (CPU vs GPU: CuPy y Numba con/sin copia)\n",
    "\n",
    "### 1) Resultados en CPU\n",
    "- **Numba `@njit` (bucle)**: **2.56 ms**  \n",
    "- **NumPy ufunc**: **8.98 ms**  \n",
    "- **Expresión NumPy directa** (`a*x**2 + b*y + c`): **8.62 ms**\n",
    "\n",
    "En este caso, **Numba en CPU es ~3.4× más rápido** que NumPy:\n",
    "- 8.62 / 2.56 ≈ **3.37×**\n",
    "Esto es coherente porque `@njit` compila el bucle a código máquina y elimina el overhead de Python, mientras que NumPy, aunque vectoriza, puede incurrir en temporales/overhead y no siempre supera a un bucle compilado eficiente.\n",
    "\n",
    "### 2) Resultados en GPU con CuPy (ufunc element-wise)\n",
    "- **CuPy CON copia (CPU↔GPU incluido)**: **7.128 ms**\n",
    "- **CuPy SIN copia (todo en GPU)**: **1.666 ms**\n",
    "\n",
    "Se observa claramente el efecto de la transferencia:\n",
    "- La versión **SIN copia es ~4.3× más rápida** que la versión con copia:  \n",
    "  7.128 / 1.666 ≈ **4.28×**\n",
    "Esto confirma que, para operaciones element-wise simples, el coste de **copiar datos** entre CPU y GPU puede dominar el tiempo total. Cuando los datos se crean y se mantienen en GPU, el cálculo paralelizado en la GPU se aprovecha mucho mejor.\n",
    "\n",
    "### 3) Resultados en GPU con Numba (`@vectorize(target='cuda')`)\n",
    "- **Numba CON copia (automática)**: **8.851 ms**\n",
    "- **Numba SIN contar copia (datos ya en GPU)**: **1.612 ms**\n",
    "\n",
    "De nuevo, la diferencia entre “con copia” y “sin copia” es grande:\n",
    "- 8.851 / 1.612 ≈ **5.49×**\n",
    "Esto encaja con lo esperado: cuando pasamos arrays de CPU, Numba debe gestionar transferencias (host↔device). Si los datos ya están en GPU y se mide solo el cómputo, se aprecia el rendimiento real del kernel/ufunc en GPU.\n",
    "\n",
    "### 4) Comparación global e interpretación\n",
    "- **Mejor tiempo absoluto observado**: GPU sin copia (**~1.6–1.7 ms**)  \n",
    "- **CPU más rápida**: Numba `@njit` (**2.56 ms**)  \n",
    "- **GPU con copia** queda más cerca de CPU: CuPy con copia (**7.13 ms**) y Numba con copia (**8.85 ms**)\n",
    "\n",
    "Conclusión principal:\n",
    "> **La GPU acelera el cálculo, pero solo se obtiene una mejora clara si se minimizan las transferencias CPU↔GPU.**  \n",
    "Para tareas simples por elemento (como `a*x^2 + b*y + c`), el “cuello de botella” suele ser la transferencia de datos. Por eso, el mayor beneficio aparece cuando los datos se generan o permanecen en GPU (sin copia).\n",
    "\n",
    "### 5) Nota sobre variabilidad (desviación estándar)\n",
    "En Numba SIN copia aparece una desviación mayor (**std ≈ 0.576 ms**) que en CuPy SIN copia (**std ≈ 0.002 ms**). Esto puede deberse a:\n",
    "- efectos de inicialización/gestión interna de memoria,\n",
    "- variabilidad del sistema,\n",
    "- y/o a que el pipeline de- y/o a que el pipeline de ejecución asíncrona y sincronización afecte a algunas repeticiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db9ddf-3a79-4360-ae42-a5aa7ea92640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5822874c-f474-4373-8b84-6e6a3fcc6f03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
