{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "454c61ba-825d-4290-b7ed-135a775fe002",
   "metadata": {},
   "source": [
    "### Numpy code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8019c56a-e5ce-469b-a406-9c6056ab9c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.05 s ± 748 μs per loop (mean ± std. dev. of 2 runs, 1 loop each)\n",
      "Result shape: (7000, 7000)\n",
      "Result type: float32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example: Large matrices (adjust size as needed)\n",
    "n = 7000  # For very large matrices, ensure you have enough RAM\n",
    "A = np.random.rand(n, n).astype(np.float32)\n",
    "B = np.random.rand(n, n).astype(np.float32)\n",
    "\n",
    "C = np.dot(A, B)  # warm-up and Matrix multiplication\n",
    "\n",
    "%timeit -r 2 -o np.dot(A, B)\n",
    "\n",
    "print(f\"Result shape: {C.shape}\")\n",
    "print(f\"Result type: {C.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6aaeba-65df-4f47-b5b6-631561ec7415",
   "metadata": {},
   "source": [
    "Celda de CuPy (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e220304-9bec-4755-94da-912417b3cbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156 ms ± 63 μs per loop (mean ± std. dev. of 2 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TimeitResult : 156 ms ± 63 μs per loop (mean ± std. dev. of 2 runs, 1 loop each)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "# Mover las matrices A y B a la memoria de la GPU\n",
    "A_gpu = cp.asarray(A)\n",
    "B_gpu = cp.asarray(B)\n",
    "\n",
    "# Warm-up (importante para ignorar el tiempo de inicialización de CUDA)\n",
    "C_gpu = cp.dot(A_gpu, B_gpu)\n",
    "\n",
    "# Medir el tiempo en GPU\n",
    "# Usamos cp.cuda.Stream.null.synchronize() para asegurar que la GPU termine antes de parar el cronómetro\n",
    "%timeit -r 2 -o cp.dot(A_gpu, B_gpu); cp.cuda.Stream.null.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5a1618-5ba8-4fd6-89c7-95ed35ca43c2",
   "metadata": {},
   "source": [
    "### Análisis de Resultados: Multiplicación de Matrices ($7000 \\times 7000$)\n",
    "\n",
    "Al comparar los tiempos obtenidos, se observa una mejora drástica en el rendimiento al utilizar hardware especializado:\n",
    "\n",
    "* **NumPy (CPU):** 1.06 segundos.\n",
    "* **CuPy (GPU):** 156 milisegundos.\n",
    "* **Speedup:** $\\approx 6.8\\times$.\n",
    "\n",
    "**Conclusiones técnicas:**\n",
    "1. **Paralelismo masivo:** La multiplicación de matrices se beneficia enormemente de los miles de núcleos CUDA de la GPU del clúster Bohr, ya que cada elemento de la matriz resultante puede calcularse de forma prácticamente independiente.\n",
    "2. **Eficiencia en punto flotante:** Al utilizar `float32`, maximizamos la capacidad de cómputo de los núcleos de precisión simple de la GPU.\n",
    "3. **Optimización de memoria:** Aunque mover matrices de $7000 \\times 7000$ a la VRAM tiene un coste, el tiempo ahorrado en el cálculo compensa con creces la transferencia inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e3ee05-8431-4a32-a4a8-e011c926ee6f",
   "metadata": {},
   "source": [
    "Celda de PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31328301-8863-4719-ace9-d86f956d8692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.13/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GeForce GTX 1080 which is of cuda capability 6.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (7.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.13/site-packages/torch/cuda/__init__.py:304: UserWarning: \n",
      "    Please install PyTorch with a following CUDA\n",
      "    configurations:  12.6 following instructions at\n",
      "    https://pytorch.org/get-started/locally/\n",
      "    \n",
      "  warnings.warn(matched_cuda_warn.format(matched_arches))\n",
      "/usr/local/lib/python3.13/site-packages/torch/cuda/__init__.py:326: UserWarning: \n",
      "NVIDIA GeForce GTX 1080 with CUDA capability sm_61 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_70 sm_75 sm_80 sm_86 sm_90 sm_100 sm_120.\n",
      "If you want to use the NVIDIA GeForce GTX 1080 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo PyTorch (GPU): 0.3286 s\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Comprobar si CUDA está disponible (debería estarlo en Bohr)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# Crear tensores directamente en la GPU\n",
    "# A y B ya los tienes definidos de las celdas anteriores\n",
    "A_torch = torch.from_numpy(A).to(device)\n",
    "B_torch = torch.from_numpy(B).to(device)\n",
    "\n",
    "# Warm-up\n",
    "C_torch = torch.matmul(A_torch, B_torch)\n",
    "\n",
    "# Medir tiempo con PyTorch\n",
    "t0 = time.perf_counter()\n",
    "C_torch = torch.matmul(A_torch, B_torch)\n",
    "torch.cuda.synchronize() # Importante para medir tiempo real en GPU\n",
    "t1 = time.perf_counter()\n",
    "\n",
    "print(f\"Tiempo PyTorch (GPU): {t1 - t0:.4f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b2c077-31e6-459d-b57b-9bd77d40856f",
   "metadata": {},
   "source": [
    "### Nota sobre la ejecución de PyTorch\n",
    "Se observa un `UserWarning` indicando que la arquitectura de la GPU (NVIDIA GeForce GTX 1080, capacidad 6.1) no es totalmente compatible con la versión de PyTorch instalada (que requiere capacidad 7.0 o superior). \n",
    "\n",
    "A pesar de la advertencia de compatibilidad, el código se ha ejecutado correctamente en la cola de **Bohr**, obteniendo un tiempo de **0.3286 s**, lo cual es significativamente más rápido que la versión de CPU, aunque ligeramente inferior al rendimiento de CuPy debido probablemente a que PyTorch no puede utilizar todos sus kernels optimizados para esta arquitectura antigua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6150373-45ad-4227-9dad-cd9f49532187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
